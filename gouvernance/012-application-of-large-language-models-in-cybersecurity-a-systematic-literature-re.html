<!doctype html>
<html lang="fr">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Application of Large Language Models in Cybersecurity: A Systematic Literature Review</title>
  <style>
:root { color-scheme: light dark; }
body { font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Arial, sans-serif;
       margin: 0; padding: 0; line-height: 1.5; }
.container { max-width: 980px; margin: 0 auto; padding: 24px; }
h1 { font-size: 1.6rem; margin: 0 0 8px; }
h2 { font-size: 1.15rem; margin: 22px 0 10px; }
.meta { display: grid; grid-template-columns: 1fr 1fr; gap: 10px 18px; margin: 12px 0 18px; }
.meta div { background: rgba(127,127,127,0.08); padding: 10px 12px; border-radius: 10px; }
.meta b { display:block; font-size: .85rem; opacity: .8; margin-bottom: 2px; }
.badges { display:flex; flex-wrap:wrap; gap: 8px; margin: 10px 0 0; }
.badge { font-size: .85rem; padding: 6px 10px; border-radius: 999px; background: rgba(127,127,127,0.12); }
.box { background: rgba(127,127,127,0.08); padding: 14px 16px; border-radius: 12px; }
pre { white-space: pre-wrap; word-break: break-word; margin: 0; font-family: inherit; }
hr { border: none; border-top: 1px solid rgba(127,127,127,0.22); margin: 18px 0; }
a { color: inherit; opacity: .95; }
.small { font-size: .92rem; opacity: .85; }
footer { margin-top: 28px; font-size: .9rem; opacity: .8; }
table { width:100%; border-collapse: collapse; }
th, td { padding: 10px 8px; border-bottom: 1px solid rgba(127,127,127,0.22); vertical-align: top; }
th { text-align: left; font-size: .9rem; opacity: .85; }
</style>
</head>
<body>
  <div class="container">
    <p class="small"><a href="index.html">← Retour à la catégorie</a></p>
    <h1>Application of Large Language Models in Cybersecurity: A Systematic Literature Review</h1>
    
    <div class="meta"><div><b>Auteurs</b>Hasanov, I.; Virtanen, S.; Hakkala, A.; Isoaho, J.</div><div><b>Année</b>2024</div><div><b>Source</b>IEEE Access</div><div><b>DOI</b><a href="https://doi.org/10.1109/ACCESS.2024.3505983" target="_blank" rel="noopener noreferrer">https://doi.org/10.1109/ACCESS.2024.3505983</a></div><div><b>Lien public</b><a href="https://doi.org/10.1109/ACCESS.2024.3505983" target="_blank" rel="noopener noreferrer">https://doi.org/10.1109/ACCESS.2024.3505983</a></div></div>

    <h2>Extrait méthode (texte original)</h2><div class='box'><pre>This article presents an exhaustive systematic literature review of 177 articles published in 2018-2024 on the application of LLMs and the use of Artificial Intelligence…</pre></div>
<p class='small'>Référence extraits : Abstract (éditeur/Scopus) ou résumé extrait</p>
    
    
    <h2>Résumé</h2><div class='box'><pre>The emergence of Large Language Models (LLMs) is currently creating a major paradigm shift in societies and businesses in the way digital technologies are used. While the disruptive effect is especially observable in the information and communication technology field, there is a clear lack of systematic studies focusing on the application and...</pre></div>
    <h2>Abstract / Texte source</h2><div class='box'><pre>The emergence of Large Language Models (LLMs) is currently creating a major paradigm shift in societies and businesses in the way digital technologies are used. While the disruptive effect is especially observable in the information and communication technology field, there is a clear lack of systematic studies focusing on the application and impact of LLMs in cybersecurity holistically. This article presents an exhaustive systematic literature review of 177 articles published in 2018-2024 on the application of LLMs and the use of Artificial Intelligence (AI) as a defensive measure in cybersecurity. This article contributes an analytical compendium of the recent research on the application of LLMs in offensive and defensive cybersecurity as well as in research on cyberethics, current legal frameworks, and research regarding the use of LLMs for cybersecurity governance. It also contributes a statistical summary of global research trends in the field. Of the reviewed literature, 68% was published in 2023. Nearly 30% of the articles originate from the USA and 11% from China, with other countries currently having significantly lower contributions to recent research. Most attention in recent research has been given to AI as a defensive measure, accounting for 27% of the reviewed literature. It was observed that LLMs have proven highly effective in phishing attack simulations and in managing cybersecurity administrative aspects, including defending against advanced exploits. Furthermore, LLMs show significant potential in the development of security software, further cementing their role as a powerful tool in cybersecurity innovation. © 2013 IEEE.</pre></div>

    <footer>Généré depuis articles_lr_tous_axes_complet_citations.xlsx</footer>
  </div>
</body>
</html>