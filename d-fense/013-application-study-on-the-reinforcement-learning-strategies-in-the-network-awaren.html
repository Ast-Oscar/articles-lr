<!doctype html>
<html lang="fr">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Application Study on the Reinforcement Learning Strategies in the Network Awareness Risk Perception and Prevention</title>
  <style>
:root { color-scheme: light dark; }
body { font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Arial, sans-serif;
       margin: 0; padding: 0; line-height: 1.5; }
.container { max-width: 980px; margin: 0 auto; padding: 24px; }
h1 { font-size: 1.6rem; margin: 0 0 8px; }
h2 { font-size: 1.15rem; margin: 22px 0 10px; }
.meta { display: grid; grid-template-columns: 1fr 1fr; gap: 10px 18px; margin: 12px 0 18px; }
.meta div { background: rgba(127,127,127,0.08); padding: 10px 12px; border-radius: 10px; }
.meta b { display:block; font-size: .85rem; opacity: .8; margin-bottom: 2px; }
.badges { display:flex; flex-wrap:wrap; gap: 8px; margin: 10px 0 0; }
.badge { font-size: .85rem; padding: 6px 10px; border-radius: 999px; background: rgba(127,127,127,0.12); }
.box { background: rgba(127,127,127,0.08); padding: 14px 16px; border-radius: 12px; }
pre { white-space: pre-wrap; word-break: break-word; margin: 0; font-family: inherit; }
hr { border: none; border-top: 1px solid rgba(127,127,127,0.22); margin: 18px 0; }
a { color: inherit; opacity: .95; }
.small { font-size: .92rem; opacity: .85; }
footer { margin-top: 28px; font-size: .9rem; opacity: .8; }
table { width:100%; border-collapse: collapse; }
th, td { padding: 10px 8px; border-bottom: 1px solid rgba(127,127,127,0.22); vertical-align: top; }
th { text-align: left; font-size: .9rem; opacity: .85; }
</style>
</head>
<body>
  <div class="container">
    <p class="small"><a href="index.html">← Retour à la catégorie</a></p>
    <h1>Application Study on the Reinforcement Learning Strategies in the Network Awareness Risk Perception and Prevention</h1>
    <div class="badges"><span class="badge">Cyberdéfense</span><span class="badge">Gestion des risques</span></div>
    <div class="meta"><div><b>Auteurs</b>Xie, J.</div><div><b>Année</b>2024</div><div><b>DOI</b><a href="https://doi.org/10.1007/s44196-024-00492-x" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/s44196-024-00492-x</a></div><div><b>Lien public</b><a href="https://doi.org/10.1007/s44196-024-00492-x" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/s44196-024-00492-x</a></div></div>

    
    <h2>Points de vue</h2><div class='box'><pre>Bilan nuancé : bénéfices mis en avant mais limites/risques discutés</pre></div>
    
    <h2>Résumé</h2><div class='box'><pre>The intricacy of wireless network ecosystems and Internet of Things (IoT) connected devices have increased rapidly as technology advances and cyber threats increase. The existing methods cannot make sequential decisions in complex network environments, particularly in scenarios with partial observability and non-stationarity. Network awareness...</pre></div>
    <h2>Abstract / Texte source</h2><div class='box'><pre>The intricacy of wireless network ecosystems and Internet of Things (IoT) connected devices have increased rapidly as technology advances and cyber threats increase. The existing methods cannot make sequential decisions in complex network environments, particularly in scenarios with partial observability and non-stationarity. Network awareness monitors and comprehends the network&#x27;s assets, vulnerabilities, and ongoing activities in real-time. Advanced analytics, machine learning algorithms, and artificial intelligence are used to improve risk perception by analyzing massive amounts of information, identifying trends, and anticipating future security breaches. Hence, this study suggests the Deep Reinforcement Learning-assisted Network Awareness Risk Perception and Prevention Model (DRL-NARPP) for detecting malicious activity in cybersecurity. The proposed system begins with the concept of network awareness, which uses DRL algorithms to constantly monitor and evaluate the condition of the network in terms of factors like asset configurations, traffic patterns, and vulnerabilities. DRL provides autonomous learning and adaptation to changing network settings, revealing the ever-changing nature of network awareness risks in real time. Incorporating DRL into risk perception increases the system&#x27;s capacity to recognize advanced attack methods while simultaneously decreasing the number of false positives and enhancing the reliability of risk assessments. DRL algorithms drive dynamic and context-aware response mechanisms, making up the adaptive network prevention component of the development. Predicting new threats and proactively deploying preventive measures, such as changing firewall rules, isolating compromised devices, or dynamically reallocating resources to reduce developing risks, is made possible by the system&#x27;s ability to learn from historical data and prevailing network activity. The suggested DRL-NARPP model increases the anomaly detection rate by 98.3%, the attack prediction accuracy rate by 97.4%, and the network risk assessment ratio by 96.4%, reducing the false positive ratio by 11.2% compared to other popular methodologies. © The Author(s) 2024.</pre></div>

    <footer>Généré depuis articles_lr_tous_axes_complet_citations.xlsx</footer>
  </div>
</body>
</html>