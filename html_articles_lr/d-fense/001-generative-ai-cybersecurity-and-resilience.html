<!doctype html>
<html lang="fr">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Generative AI cybersecurity and resilience</title>
  <style>
:root { color-scheme: light dark; }
body { font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Arial, sans-serif;
       margin: 0; padding: 0; line-height: 1.5; }
.container { max-width: 980px; margin: 0 auto; padding: 24px; }
h1 { font-size: 1.6rem; margin: 0 0 8px; }
h2 { font-size: 1.15rem; margin: 22px 0 10px; }
.meta { display: grid; grid-template-columns: 1fr 1fr; gap: 10px 18px; margin: 12px 0 18px; }
.meta div { background: rgba(127,127,127,0.08); padding: 10px 12px; border-radius: 10px; }
.meta b { display:block; font-size: .85rem; opacity: .8; margin-bottom: 2px; }
.badges { display:flex; flex-wrap:wrap; gap: 8px; margin: 10px 0 0; }
.badge { font-size: .85rem; padding: 6px 10px; border-radius: 999px; background: rgba(127,127,127,0.12); }
.box { background: rgba(127,127,127,0.08); padding: 14px 16px; border-radius: 12px; }
pre { white-space: pre-wrap; word-break: break-word; margin: 0; font-family: inherit; }
hr { border: none; border-top: 1px solid rgba(127,127,127,0.22); margin: 18px 0; }
a { color: inherit; opacity: .95; }
.small { font-size: .92rem; opacity: .85; }
footer { margin-top: 28px; font-size: .9rem; opacity: .8; }
table { width:100%; border-collapse: collapse; }
th, td { padding: 10px 8px; border-bottom: 1px solid rgba(127,127,127,0.22); vertical-align: top; }
th { text-align: left; font-size: .9rem; opacity: .85; }
</style>
</head>
<body>
  <div class="container">
    <p class="small"><a href="index.html">← Retour à la catégorie</a></p>
    <h1>Generative AI cybersecurity and resilience</h1>
    <div class="badges"><span class="badge">Gouvernance</span></div>
    <div class="meta"><div><b>Auteurs</b>Radanliev, P.; Santos, O.; Ani, U.D.</div><div><b>Année</b>2025</div><div><b>DOI</b><a href="https://doi.org/10.3389/frai.2025.1568360" target="_blank" rel="noopener noreferrer">https://doi.org/10.3389/frai.2025.1568360</a></div><div><b>Lien public</b><a href="https://doi.org/10.3389/frai.2025.1568360" target="_blank" rel="noopener noreferrer">https://doi.org/10.3389/frai.2025.1568360</a></div></div>

    
    <h2>Points de vue</h2><div class='box'><pre>Plutôt critique/prudent : met l&#x27;accent sur limites/risques</pre></div>
    <h2>Limites identifiées</h2><div class='box'><pre>While these capabilities are advancing at pace, their deployment raises profound ethical, security, and privacy concerns that remain...</pre></div>
    <h2>Résumé</h2><div class='box'><pre>Generative Artificial Intelligence marks a critical inflection point in the evolution of machine learning systems, enabling the autonomous synthesis of content across text, image, audio, and biomedical domains. While these capabilities are advancing at pace, their deployment raises profound ethical, security, and privacy concerns that remain...</pre></div>
    <h2>Abstract / Texte source</h2><div class='box'><pre>Generative Artificial Intelligence marks a critical inflection point in the evolution of machine learning systems, enabling the autonomous synthesis of content across text, image, audio, and biomedical domains. While these capabilities are advancing at pace, their deployment raises profound ethical, security, and privacy concerns that remain inadequately addressed by existing governance mechanisms. This study undertakes a systematic inquiry into these challenges, combining a PRISMA-guided literature review with thematic and quantitative analyses to interrogate the socio-technical implications of generative Artificial Intelligence. The article develops an integrated theoretical framework, grounded in established models of technology adoption, cybersecurity resilience, and normative governance. Structured across five lifecycle stages (design, implementation, monitoring, compliance, and feedback) the framework offers a practical schema for evaluating and guiding responsible AI deployment. The analysis reveals a disconnection between the fast adoption of generative systems and the maturity of institutional safeguards, resulting with new risks from the shadow Artificial Intelligence, and underscoring the need for adaptive, sector-specific governance. This study offers a coherent pathway towards ethically aligned and secure application of Artificial Intelligence in national critical infrastructure. © © 2025 Radanliev, Santos and Ani.</pre></div>

    <footer>Généré depuis articles_lr_tous_axes_complet_citations.xlsx</footer>
  </div>
</body>
</html>